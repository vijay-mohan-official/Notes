System Design
System design is the process of designing the elements of a system such as architecture, modules and components, the different interfaces of those components and the data that goes through that system.

Types of System Design
HLD  -  High-Level Design
Describes the main components that would be developed for the resulting product.
The system architecture details, database design, services and processes, the relationship between various modules and features.

LLD  -  Low-Level Design
Describes the design of each element mentioned in the High-Level Design of the system.
Classes, interfaces, relationships between different classes, and actual logic of the various components.




Monolithic Architecture
Architecture - Internal design details for building the applications.
Web Application with Front-End, Back-End and Data Storage written and deployed together is called monolithic architecture.

If all the components and functionalities of a project are entangled and combined in a single codebase, then that is a monolithic application.
Monolithic architecture has less complexity ---> Easier to understand --> Higher productivity
Monolithic system is also known as centralized system.

Advantages
Best architecture if you're a beginner and just starting.
Since all modules are present in the single system, they require fewer network calls as compared to other architectures.
Comparatively easier to secure monolithic system.
Integration testing is easier and lesser confusion.

Disadvantages
In monolithic architecture, every module is combined in a single system, so if there is an error or bug in a single module, it can destroy the complete system.
Whenever a single module is updated, the whole system needs to be updated to reflect the changes to user. All modules are present in a single system and are connected to one another, so the whole system needs to be updated.
If there is any change in a single module's programming language or framework, it can affect the entire system. The entire system needs to be changed because every module is interlinked and tightly coupled.




Distributed System
A distributed system is a collection of multiple individual systems connected through a network that share resources, communicate and coordinate to achieve common goals.

Advantages
Scalable : Easy to scale horizontally(We can add more machines to improve scalability)
No Single Point of Failure
Low Latency

Disadvantages
Complex as there are multiple servers involved
Additional management required to handle resources(Load balancing etc)
Difficult to secure
Messages may be lost in between nodes




Latency
Latency = Network delay + Computational delay
Monolithic doesn't involve network delay and hence is faster than distributed systems

Reducing Latency
1. Caching : Add a caching layer in b/w user and server
Caching is the process of storing information for a set period of time on a computer

2. Continuous Delivery Network(CDN) : Used to store static data that doesn't change often
CDNs are geographically distributed networks of proxy servers and their objective is to serve content to users more quickly.

3. Upgrading : Upgrading of hardware




Throughput
The volume of work or information flowing through a system.

Throughput is the amount of data transmitted per unit of time.
It is the process flow rate.
Throughput is measured in bits per second, i.e, bps.

Throughput will be more in distributed systems.(No limit in resources, load balancer)

Causes of Low Throughput
Latency
Protocol Overhead(Handshake needed b/w two servers)
Congestion(All requests coming at the same time)

Improving Throughput
CDN
Caching
Distributed system
Load balancer
Improve resources of system




Availability
Fault tolerance is directly proportional to availability.
Distributed systems have higher availabilty than monolithic architecture.

How to increase availability?
1. Replication
Replication includes dependency, but involves the copying of data from one node to another or the synchronization of state between nodes.

2. Distributed systems

3. Redundancy
Redundancy is the duplication of nodes, in case of some of them are failing.




Consistency
When more than one client requests the system, for all such requests, it will be called consistent when each client gets the same data. 
The data should always be consistent, regardless of who is accessing it.

When more than one client requests the system, for all such requests, when different clients get different responses due to some recent update that has not been committed to all systems yet, this reading operation will be called dirty read.

Factors improving consistency
1. Improving network bandwidth
2. Stop the read - Stop the read operation, until all servers are updated and synchronized
3. Replication based on Distance aware strategies - Place servers that require synchronization close to each other

Types of consistency
1. Strong consistency
When the system doesn't allow read operation until all the nodes are with replicated data are updated.

2. Eventual Consistency
User Read Requests are not halted till all the replicas are updated rather the update process is eventual. Some users might recieve old data but eventually all the data is updated to the latest data.

3. Weak Consistency
No need for synchronization, may or may not happen.




CAP Theorem
CAP --> Consistency, Availability and Partition Tolerance

For a distributed system, the CAP Theorem states that it is possible to attain only two properties and the third would be always compromised.
The system requirements should define which two properties should be chosen over the rest.

The system designer can select Consistency and Partition Tolerance but the Availability would be compromised then.
  Should avoid dirty read scenario, hence availability will be compromised for some time until synchronized.

The system designer can select Partition Tolerance and Availability but the Consistency would be compromised then.
  In social media, if a user posts now and immediately if its not reflected instantly in your feed it is not as issue.

The system designer can select Availability and Consistency but the Partition Tolerance would be compromised then.
  System will be centralized, one node, monolithic architecture.

Partition Tolerance cannot be compromised and hence when designing systems it comes down to either compromising Consistency or Availability.
Eg : What can be compromised in below systems?
a) Blogs website -> Consistency
b) Multiplayer online games -> Consistency
c) Stock trading platforms -> Availability
d) Video Streaming sites -> Consistency
e) Ticket Booking System -> Availability
f) Video chat applications -> Consistency
g) Bank -> Availability




Lamport Logical Clock
Lamport's Logical Clock is a mechanism for determining the order of events in a distributed system, where events can occur concurrently and there is no global clock.

How It Works:
Each process maintains a counter (logical clock) that starts at zero.
Before an event occurs (like sending a message), the process increments its counter.
When a process sends a message, it includes its current timestamp.
Upon receiving a message, the receiving process updates its counter to be greater than its current value and the timestamp in the message.




Scalability
Scalability refers to the ability of a system, network, or process to handle a growing amount of work, or its potential to accommodate growth.

Vertical Scalability
Pros:
Involves adding more resources (CPU, RAM, storage) to an existing machine.
Easy implementation.
Less power.(Only one machine is scaled and hence lesses power)
Management is easy.

Cons:
Single point of failure.
There is a limit for upgrading.

Horizontal Scaling
Involves adding more machines or nodes to a system.
Typically more complex but can provide greater resilience and capacity.

Pros:
No Single point of failure.

Cons:
Management is difficult.
Power consumption is higher.
Securing applications is also tougher.




Redundancy
Redundancy is simply the duplication of nodes or components so that when a node or component fails, the duplicate node is available to service components.

Active Redundancy is considered when each unit is operating/active and responding to the action. Multiple nodes are connected to a load balancer and each unit receives an equal load

Passive Redundancy is considered when one node is active or operational and the other is not operating. During the breakdown of the active node, the passive node maintains availability by becoming the active node.




Replication
Replication = Redundancy + Synchronization

Active Replication
If a read-write operation is happening in a DB which is hosted on multiple nodes, read-write will happen in all the nodes and become synchronized.

Passive Replication
Every read-write -> master
If master goes down one slave becomes master.

Master-slave replication can be either synchronous or asynchronous. The difference is simply the timing of propagation of changes.
If the changes are made to the master and slave at the same time, it is synchronous.
If changes are queued up and written later, it is asynchronous.




Load Balancers
Load balancing is the process of efficient distribution of network traffic across all nodes in a distributed system.

Roles of load balancer
1. The load distribution is equal over every node.
2. Health check(if the node is not operational, the request is passed to another node that is up and running)
3. Load balancers ensure high scalability, high throughput and high availability.

When to use it and when not to use it?
In monolithic or in case of vertically scaled system, we don't need it. But in microservice architecture, we need it.

Challenges of load balancing
Single Point of Failure:
During a load balancer malfunctioning, the communication between clients and servers would be broken.
To solve this issue, we can use redundancy. The system can have an active load balancer and one passive load balancer.

Advantages of using load balancer
1. Optimization : Load balancers help in resource utlilization and lower response time, thereby optimizing the system in a high traffic environment
2. Better user experience : Load balancers help in reducing the latency and increasing availability making the user's request go smoothly and error-free.
3. Prevents Downtime : Load balancers maintain a record of servers that are non-operational and distribute the traffic accordingly, therefore ensuring security and preventing downtime, which also increases profit and productivity.
4. Flexibility : Load balancers have the flexibility to re-route the traffic in case of breakdown and work on server maintainance to ensure efficiency. This helps in avoiding traffic bottlenecks.
5. Scalability : When the traffic of a web application increases suddenly, load balancers can use physical and virtual servers to deliver the responses without any disruption.
6. Redundancy : Load balancing also provides in-build redundancy by re-routing the traffic in case of any failure.

Load Balancing Algorithms
1. Round Robin (Static) : Rotation fashion
2. Weighted Round Robin (Static) : It is similar to Round Robin when the servers are of different capacities.(some node can have better resources, others might not have)  
3. IP Hash Algorithm (Static) : The servers have almost equal capacity, and the hash function(input is source IP) is used for random or unbiased distribution of requests to the nodes.
4. Source IP Hash (Static) : Source IP Hash combines the server and client's source and destination IP addresses  to produce a hash key. The key can be used to determine the request distribution.
5. Least Connection Algorithm (Dynamic): Client requests are distributed to the application server with the least number of active connections at the time the client request is recieved.
6. Least Response Time (Dynamic) : The request is distributed based on the server which has the least response time.




Caching
Caching is a technique used to temporarily store frequently accessed data in a high-speed storage layer (such as memory) to improve retrieval times and reduce the load on primary data sources.

Types of Caching
1. In-memory/Local cache - Cache content locally in the server. Eg: MemCache
2. Distributed/Extrenal Cache Eg : Redis

When to use?
1. When the app is read intensive
2. When the app has lot of static content

Content Delivery Network(CDN)
CDNs are geographically distributed networks of proxy servers and their objective is to serve content to users more quickly. Mostly used to store static contents.

Cache Eviction Strategies
Cache Miss : API tries to fetch data from Cache, but not available.

1. Least Recently Used(LRU) : Remove the leastly used data stored in cache.
2. Most Recently Used(MRU) : Remove the most recently used data stored in cache.
3. Least Frequently Used(LFU) : Remove the leastly accessed data stored in cache.
4. First In First Out(FIFO) : If there is a limit set in cache and data has reached the limit, remove the first cached data when a new data comes.
5. Last In First Out(LIFO) : If there is a limit set in cache and data has reached the limit, remove the last cached data when a new data comes.
6. Random Replacement(RR) : Randomly evict data from cache.




File Based Storage System
A file based storage system is a database management system where data is stored in the form of files.

Challenges of File Based Storage System
1. Data Redundancy : Update anomaly, delete anomaly leading to data inconsistency
2. Poor Security : Same data are present in the system which causes a possibility of data breaches by unauthorized users.
3. Slow Speed : Speed is very slow and data retrieval is not very efficient.

To overcome these challenges we use relational database management systems.(RDBMS)




Relational Database Management Systems(RDBMS)
Definiton of RDBMS
Software - That performs data operations on relational database.
Operations - Store, manage, query and retrieve data.
Tables - Data is represented in the form of tables.
Foreign Keys - The relationship between the two tables is represented by foreign keys.

Advantages
No data redundancy and inconsistency.
Data Concurrency : A locking system is provided by RDBMS to prevent abnormalities from occuring.
Data Searching : Built-in searching capabilities(No need of a seperate programme as in FS(File Based Storage System))
Data Integrity : Eg: To maintain data integrity, numeric columns won't have alphabet data.(There is no process in the File Based Storage System to check these constraints automatically)

Problems
Rigid Schema : No flexibility and we should follow the structure that is defined.
High Cost
Scalability Issues : Horizontal scaling/ sharding is very difficult.




NoSQL
NoSQL stands for "non-SQL" database or we can say that it is a non-relational database.

NoSQL is the umbrella term comprising of four different types of databases.
1. Key value DB
Generally used for caching. 
Eg: Redis

2. Document DB
Brings best of both RDBMS and NoSQL.
It combines the relationship concept from RDBMS and dynamic schema and horizontal scaling from NoSQL databases.
Eg: MongoDB

3. Columnar DB
The columns are stored together instead of rows.
Because of that, the aggregations in such databases is rapid. It is widely used for Data Analysis.
Used when we query on a subset of your data's columns.
Because columnar DB just needs to read these specific columns, it conducts such queries quickly(while row-based DB would have to read the entire data)
Eg : Cassandra

4. Graph DB
Graph database represents and stores entities and relationships in the form of graph data structure. It is mainly used for social networks.
Eg: Neo4j

DB Selection based on app requirement :
Google Maps : Graph DB
LinkedIn : Graph DB
Shopping Website Cart Page : Key Value DB
Score Card : Key Value DB
Machine Learning and Data Analysis : Columnar DB
Payments : Should be consistent, hence should not use NoSQL, always use RDBMS.

Polyglot Persistence
If an application's needs cannot be satisfied by a single type of DB, we use multiple DBs. This is called polyglot persistence.

Eg:                      E-Commerce Platform
                                  |
-------------------------------------------------------------------------
|                          |                         |                  |
Shopping Cart            Completed               Inventory         Customer Social Graph
    &                      Order                     &                  |
Session Data               |                     Item Price           Graph Store 
    |                    Document Store              |
Key Value Store                                     RDMS
                                                  (LegacyDB)

Normalization and Denormalization
Putting data into multiple tables to avoid redundancy is called normalization.
Eg : For Student and Department Relation, we create a table called department for department details and add the dept_id in student table to avoid redundant department data in Student table.

Denormalization combines the data and organizes it in a single table.
It is the process of adding redundant data to the normalized relational database to optimize its performance.

Benefits of Denormalization
1. Faster read and write operations.
2. Management convenience.(Can avoid joins)
3. High data availability.
4. Reduces the number of network calls to fetch data from multiple places.

Challenges of Denormalization
1. Redundant data - Wastage of memory.
2. It increases the complexity.
3. Data inconsistency.
4. It will slow read write operations since we will need to write multiple places due to redundancy.

Indexing
Indexing creates a lookup table with the column and the pointer to the memory location of the row, containing this column.
When we create an index for a column in a table, it stores in a seperate memory location the sorted column and pointer to the table row.

B-Trees data structure is used to store the indexing as it is a multilevel format of tree-based indexing, which has balanced binary search tress.
Before indexing searching queries had a time complexity of O(n), after indexing, it becomes O(log n).

Indexing shouldn't be added for all tables, it should be added for tables which are read-intensive.
Also, if a table is write-intensive in nature, we shouldn't use indexing.(For every insertion, at the seperate memory location where indexing table is present we need to do an insertion and perform sorting)




Synchronous communication(Blocking call)
We block our time and wait for some process to be completed to perform further tasks.
A client sends a request to the server and will wait until the response is received to perform any other request.
Used to achive consistency and during transactions.

Industrial Use Cases :
1. Stock Market
2. Bank Payments
3. Ticket Booking
4. Real Time Decision Making

Asynchronous Communication(Non Blocking Call)
We don't need to block our time and can perform other operations.
No need to wait for the response from the server.

Scenarios :
Adding an item to Amazon Cart - Synchronous Communication - Application waits for this response before allowing the user to add the project into the cart.
Proceeding with payment - Synchronous Communication - Application waits till the confirmation of payment has been successfully received from the bank. 
Sending order placed notification - Asynchronous Communication - It can take some time for the notification to arrive, but in the meantime, a user can do anything on the application without waiting for the notification.

Where is it necessary? (Asynchronous Communication)
1. Computation takes a lot of time
2. Scalability of application
3. Avoid cascading failure

Message Based Communication
Client sends request in the form of a message.
Receives response in the form of a message.
It is async, so client is not required to halt or wait for the process.

It has a producer(produces message), consumer(consumes message) and agent(medium/channel through which message is passed).
Agent is generally a queue which follows FIFO principle.
Eg : Kafka, RabbitMQ

P2P Model(Peer to Peer)
Two parties are involved.
Eg: When sending a mail to another person, it takes some time to receive the mail as the communication is async.

Publish Subscribe Model
Multiple parties are involved.
1 producer but multiple consumers.
Eg: Subsciption to newsletters




Web Server
Tools or programs that help keep the web application always up and running.
It can refer to hardware or software, or both of them working together.

On the hardware side, a web server is a computer that stores web server software and a website's component files(for example, HTML documents, images, CSS stylesheets and JavaScript files). A web server connects to the Internet and supports physical data interchange with other devices connected on web.
