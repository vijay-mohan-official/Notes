Kafka
Kafka is an open source distibuted event streaming platform.
Kafka is designed to handle data that is constantly being generated and needs to be processed as it comes in, without delays.

Basic Kafka Terminologies
Kafka Cluster : Group of Kafka brokers
Kafka Producer : Writes new data into the Kafka cluster
Kafka Consumer : Consumes data present in the Kafka cluster
Zookeeper : Keeps track of Kafka cluster health
Kafka Connect : If you need to bring data from an external entity(DB, file etc), you use Kafka connect to bring in the data into cluster or out of cluster without writing any code(Declarative Integration) Store data from Source to cluster and fetch data from cluster to Sink.
Kafka Stream : Functionalities used for data transformation on data fetched from cluster.
Topics : Like a table, where we store similar data

Commands
To start Zookeeper from bin/windows folder :
zookeeper-server-start.bat ..\..\config\zookeeper.properties

To start Kafka broker from bin/windows folder :
kafka-server-start.bat ..\..\config\server.properties

To create a topic in Kafka broker from bin/windows folder :
kafka-topics.bat --create --topic my-topic --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3

To create a producer which produces data to a topic :
kafka-console-producer.bat --broker-list localhost:9092 --topic my-topic

To create a consumer which consumes data from a topic :
kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic my-topic --from-beginning
--from-beginning flag is used to fetch all messages stored in broker from the start 

Topics and Partitions
Topics
Named container for similar events. 
Unique identifier of a topic is its name.
Eg : Student topic will have student related data and Food topic will have food related data.

They are like tables in a database
Producers produce a message into the topic(ultimately to partitions in round robin fashion) or directly into partitions.
Consumer poll continuously for new messages using the topic name.

Partitions
A topic is spilt into several parts called partitions and distributed to Kafka brokers in round robin fashion to achieve distributed system.
Partitions is where actually the message is located inside the topic.
Therefore while creating topics, we need to specify the number of partitions(the number is arbitrary and can be changed later).
Each partition is an ordered, immutable sequence of records.
Each partition is independent of each other.
Each message gets stored into partitions with an Incremental id known as Offset value.
Ordering is there only at partition level.(So, if data should be stored in order, then do it on same partition)
Partition continuously grows(offset increases) as new records are produced.
All the records exist in distributed log file.

Replication Factor : A partition is replicated by this factor and it is replicated in another broker to prevent fault tolerance.

If a message is send without a key, then data will be stored in Kafka partitions in round robin fashion.
But if a messages are send with the same key, then partitioner will apply hashing techniques and store them in the same partition.
Note: We can send message with or without key, i.e, key is optional.

When sending messages with key, ordering will be maintained as they will be in the same partition.
Without key, we cannot guarantee the ordering of message as consumer poll the messages from all the partitions at the same time.

Consumer Offset 
Position of a consumer in a specific partition of a topic.
It represents the latest message consumer has read.
When a consumer group reads messages from a topic, each member of the group maintains its own offset and updates it as it consumes messages.

Consumer offset is stored in a topic named __consumer_offset.
__consumer_offset is a built-in topic in Apache Kafka that keeps track of the latest offset committed to each partition of each consumer group.
The topic is internal to the Kafka cluster and not meant to be read or written to directly by clients. 
Instead, the offset information is stored in the topic and updated by the Kafka broker to reflect the position of each consumer in each partition.
The information in __consumer_offset is used by Kafka to maintain the reliability of the consumer groups and to ensure that messages are not lost or duplicated.

There is a seperate __consumer_offset topic created for each consumer group. So, if you have 2 consumer groups containing 4 consumers each, you will have a total of 2 __consumer_offset topics created.
The __consumer_offset topic is used to store the current offset of each consumer in each partition for a given consumer group. Each consumer in the group updates its own offset for the partitions it is assigned in the __consumer_offset topic, and the group coordinator uses this information to manage the assignment of partitions to consumers and to ensure that each partition is consumed by exactly one consumer in the group.

When a consumer joins a consumer group, it sends a join request to the group coordinator.
The group coordinator determines which partitions in the consumer should be assigned based on the number of consumers in the group and the current assignment of partitions to consumers.
The group coordinator then sends a new assignment of partitions to the consumer, which includes the set of partitions that the consumer is responsible for consuming.
The consumer starts consuming data from the assigned partitions.

It is important to note that consumers in a consumer group are always assigned partition in a "sticky" fashion, meaning that a consumer will continue to be assigned the same partitions as long as it remains in the group. This allows consumers to maintain their position in the topic and continue processing where they left off, even after a rebalance.

Command to fetch all topics in Kafka :
kafka-topics.bat --bootstrap-server=localhost:9092 --list

Command to fetch all consumer groups in Kafka :
kafka-consumer-groups.bat --bootstrap-server=localhost:9092 --list

To describe and get details of topic and partitions :
.\kafka-topics.bat --describe --topic=my-topic --bootstrap-server=localhost:9092




Kafka commands
Start Zookeeper : 
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties

Start Kafka Broker Service : 
.\bin\windows\kafka-server-start.bat .\config\server.properties

Creating a Kafka topic to store events : 
.\bin\windows\kafka-topics.bat --create --topic <TOPIC NAME> --bootstrap-server <KAFKA SERVER URL>

Eg : .\bin\windows\kafka-topics.bat --create --topic topic_demo --bootstrap-server localhost:9092

Producer writing some events into a topic : 
.\bin\windows\kafka-console-producer.bat --topic <TOPIC NAME> --bootstrap-server <KAFKA SERVER URL>

Eg : .\bin\windows\kafka-console-producer.bat --topic topic_demo --bootstrap-server localhost:9092
	> hello world
	> hi
	
Consumer consuming/reading events : 
.\bin\windows\kafka-console-consumer.bat --topic <TOPIC NAME> --from-beginning --bootstrap-server <KAFKA SERVER URL>

Eg : .\bin\windows\kafka-console-consumer.bat --topic topic_demo --from-beginning --bootstrap-server localhost:9092


Command to see created topics :
.\bin\windows\kafka-topics.bat --bootstrap-server localhost:9092 --list

Command to see data available in created topics :
.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic your_topic_name --from-beginning

.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic wikimedia_recentchange --from-beginning
